{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00d955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f36b3ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Handhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Handhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19c95cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_id = set(stopwords.words('indonesian'))\n",
    "\n",
    "def bersihkan_teks(teks):\n",
    "    # 1. Hilangkan header/footer/nama pengadilan\n",
    "    teks = re.sub(r'^(MAHKAMAH.*?PUTUSAN).*', '', teks, flags=re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # 2. Hilangkan karakter non-alfabet\n",
    "    teks = re.sub(r'[^\\w\\s]', ' ', teks)\n",
    "\n",
    "    # 3. Normalisasi: huruf kecil\n",
    "    teks = teks.lower()\n",
    "\n",
    "    # 4. Tokenisasi\n",
    "    tokens = word_tokenize(teks)\n",
    "\n",
    "    # 5. Hapus stopword\n",
    "    tokens = [t for t in tokens if t not in stopwords_id and len(t) > 2]\n",
    "\n",
    "    # 6. Gabung kembali jadi string\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff87268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Handhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Handhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Only needed once\n",
    "nltk.download('stopwords')  # Only needed once\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def bersihkan_teks(teks):\n",
    "    tokens = word_tokenize(teks)  # Will now work\n",
    "    # ... rest of your cleaning code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf914ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Handhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Handhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 33/33 [00:01<00:00, 25.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK data if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize Indonesian stopwords\n",
    "stopwords_id = set(stopwords.words('indonesian'))\n",
    "\n",
    "def bersihkan_teks(teks):\n",
    "    \"\"\"\n",
    "    Clean and preprocess Indonesian text by:\n",
    "    1. Removing special characters/numbers\n",
    "    2. Converting to lowercase\n",
    "    3. Tokenizing\n",
    "    4. Removing stopwords\n",
    "    5. Joining back into clean text\n",
    "    \"\"\"\n",
    "    # 1. Remove special characters and numbers\n",
    "    teks = re.sub(r'[^a-zA-Z\\s]', '', teks)\n",
    "    \n",
    "    # 2. Convert to lowercase\n",
    "    teks = teks.lower()\n",
    "    \n",
    "    # 3. Tokenize\n",
    "    tokens = word_tokenize(teks)\n",
    "    \n",
    "    # 4. Remove stopwords and short words\n",
    "    tokens = [t for t in tokens if t not in stopwords_id and len(t) > 2]\n",
    "    \n",
    "    # 5. Join back into clean text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Folder paths\n",
    "folder_txt = \"data/extracted_texts/\"\n",
    "folder_cleaned = \"data/cleaned_txt/\"\n",
    "os.makedirs(folder_cleaned, exist_ok=True)\n",
    "\n",
    "# Process all text files\n",
    "for nama_file in tqdm(os.listdir(folder_txt)):\n",
    "    if nama_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder_txt, nama_file), \"r\", encoding=\"utf-8\") as f:\n",
    "            teks_mentah = f.read()\n",
    "\n",
    "        teks_bersih = bersihkan_teks(teks_mentah)\n",
    "\n",
    "        with open(os.path.join(folder_cleaned, nama_file), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(teks_bersih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9dcde7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ekstrak_metadata(teks):\n",
    "    metadata = {}\n",
    "\n",
    "    nomor = re.search(r\"nomor\\s*:?\\s*([\\w./-]+)\", teks, re.IGNORECASE)\n",
    "    tanggal = re.search(r\"tanggal putusan\\s*:?\\s*([^\\n]+)\", teks, re.IGNORECASE)\n",
    "    pasal = re.findall(r'pasal\\s+\\d+\\s*(?:ayat\\s+\\(\\d+\\))?', teks, re.IGNORECASE)\n",
    "\n",
    "    metadata[\"nomor_perkara\"] = nomor.group(1) if nomor else None\n",
    "    metadata[\"tanggal\"] = tanggal.group(1) if tanggal else None\n",
    "    metadata[\"pasal\"] = pasal\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02a40e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = {\n",
    "    \"nama_file\": nama_file,\n",
    "    \"metadata\": ekstrak_metadata(teks_bersih),\n",
    "    \"teks_bersih\": teks_bersih\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f0aa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "semua_case = []\n",
    "for file in os.listdir(\"data/cleaned_txt\"):\n",
    "    with open(os.path.join(\"data/cleaned_txt\", file), \"r\", encoding=\"utf-8\") as f:\n",
    "        teks = f.read()\n",
    "    case = {\n",
    "        \"nama_file\": file,\n",
    "        \"metadata\": ekstrak_metadata(teks),\n",
    "        \"teks_bersih\": teks\n",
    "    }\n",
    "    semua_case.append(case)\n",
    "\n",
    "with open(\"case_base.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(semua_case, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0ebc6",
   "metadata": {},
   "source": [
    "Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38ebe9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"data/cleaned_txt\"\n",
    "dokumen = []\n",
    "\n",
    "for nama_file in os.listdir(folder):\n",
    "    if nama_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder, nama_file), \"r\", encoding=\"utf-8\") as f:\n",
    "            teks = f.read()\n",
    "        dokumen.append({\n",
    "            \"nama_file\": nama_file,\n",
    "            \"teks\": teks\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(dokumen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e99a103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # kamu bisa ubah jumlah fitur\n",
    "X_tfidf = vectorizer.fit_transform(df['teks'])\n",
    "\n",
    "print(X_tfidf.shape)  # jumlah dokumen x jumlah fitur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ae4ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case (1).txt → Top words: ['lembar', 'agung', 'nomor', 'mahkamah', 'tanggal']\n",
      "case (10).txt → Top words: ['agung', 'mahkamah', 'nomor', 'indonesia', 'republik']\n",
      "case (11).txt → Top words: ['pendukungnya', 'astica', 'agung', 'mahkamah', 'nomor']\n",
      "case (12).txt → Top words: ['agung', 'mahkamah', 'nomor', 'bpkb', 'vinoli']\n",
      "case (13).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'informasi']\n",
      "case (14).txt → Top words: ['monta', 'perkasa', 'agung', 'mahkamah', 'indonesia']\n",
      "case (15).txt → Top words: ['piece', 'indonesia', 'master', 'agung', 'mahkamah']\n",
      "case (16).txt → Top words: ['agung', 'mahkamah', 'penyiaran', 'indonesia', 'republik']\n",
      "case (17).txt → Top words: ['mahkamah', 'agung', 'republik', 'indonesia', 'informasi']\n",
      "case (18).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'samarinda']\n",
      "case (19).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'medan']\n",
      "case (2).txt → Top words: ['nestle', 'pajak', 'copy', 'indonesia', 'pertambahan']\n",
      "case (20).txt → Top words: ['lembarfaktur', 'nomor', 'agung', 'mahkamah', 'pajak']\n",
      "case (21).txt → Top words: ['nomor', 'agung', 'mahkamah', 'setfaktur', 'republik']\n",
      "case (22).txt → Top words: ['lembar', 'cst', 'agung', 'mahkamah', 'nocst']\n",
      "case (23).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'nomor']\n",
      "case (24).txt → Top words: ['agung', 'mahkamah', 'nomor', 'indonesia', 'republik']\n",
      "case (25).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'nomor']\n",
      "case (26).txt → Top words: ['bal', 'isi', 'bungkus', 'slop', 'batang']\n",
      "case (27).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'nomorketeranganppnwpjkpfotokopilegalisir']\n",
      "case (28).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'ganani']\n",
      "case (29).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'nomor']\n",
      "case (3).txt → Top words: ['agung', 'mahkamah', 'peninjauan', 'republik', 'indonesia']\n",
      "case (30).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'nomor']\n",
      "case (31).txt → Top words: ['agung', 'mahkamah', 'balla', 'indonesia', 'republik']\n",
      "case (32).txt → Top words: ['muldiyanto', 'andar', 'doni', 'irsan', 'tampubolon']\n",
      "case (33).txt → Top words: ['set', 'pendukungnya', 'fotokopi', 'dokumen', 'kudangan']\n",
      "case (4).txt → Top words: ['cst', 'lembar', 'nomor', 'agung', 'mahkamah']\n",
      "case (5).txt → Top words: ['agung', 'mahkamah', 'indonesia', 'republik', 'nomor']\n",
      "case (6).txt → Top words: ['agung', 'mahkamah', 'cukai', 'indonesia', 'republik']\n",
      "case (7).txt → Top words: ['agung', 'mahkamah', 'republik', 'indonesia', 'puluh']\n",
      "case (8).txt → Top words: ['dilegalisir', 'agung', 'mahkamah', 'fotokopi', 'indonesia']\n",
      "case (9).txt → Top words: ['agung', 'mahkamah', 'nomor', 'indonesia', 'republik']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "for i, row in enumerate(X_tfidf.toarray()):\n",
    "    top_idx = row.argsort()[-5:][::-1]  # 5 kata terpenting\n",
    "    top_words = [feature_names[j] for j in top_idx]\n",
    "    print(f\"{df.iloc[i]['nama_file']} → Top words: {top_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c86b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"terdakwa membawa sabu dan melanggar pasal 114 uu narkotika\"\n",
    "query_vec = vectorizer.transform([query])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "caefed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 kasus paling mirip:\n",
      "case (19).txt (score: 0.124)\n",
      "case (16).txt (score: 0.117)\n",
      "case (18).txt (score: 0.114)\n",
      "case (30).txt (score: 0.109)\n",
      "case (15).txt (score: 0.097)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = cosine_similarity(query_vec, X_tfidf).flatten()\n",
    "top_k = similarities.argsort()[-5:][::-1]\n",
    "\n",
    "print(\"Top 5 kasus paling mirip:\")\n",
    "for idx in top_k:\n",
    "    print(f\"{df.iloc[idx]['nama_file']} (score: {similarities[idx]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68c8a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efbad338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indobenchmark/indobert-base-p1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0eecfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_embed(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state  # [1, seq_len, hidden_size]\n",
    "    embeddings = last_hidden_state.mean(dim=1)     # [1, hidden_size]\n",
    "    return embeddings.squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98fb3f",
   "metadata": {},
   "source": [
    "Case  Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9584ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:02<00:00, 12.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "folder = \"data/cleaned_txt\"\n",
    "vectors = []\n",
    "filenames = []\n",
    "\n",
    "for file in tqdm(os.listdir(folder)):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Buat vektor IndoBERT\n",
    "        try:\n",
    "            vec = bert_embed(text)\n",
    "            vectors.append(vec)\n",
    "            filenames.append(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Gagal embed {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "79b3babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/processed/cases.csv\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.to_csv(\"data/processed/train.csv\", index=False)\n",
    "test_df.to_csv(\"data/processed/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bcd9cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, vectors, filenames, k: int = 5):\n",
    "    # 1) Preprocess query (opsional)\n",
    "    # 2) Hitung vektor query\n",
    "    query_vec = bert_embed(query)\n",
    "\n",
    "    # 3) Hitung cosine similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarities = cosine_similarity([query_vec], vectors).flatten()\n",
    "\n",
    "    # 4) Ambil top-k indeks\n",
    "    top_k = similarities.argsort()[-k:][::-1]\n",
    "\n",
    "    # 5) Kembalikan list case_id atau nama file\n",
    "    return [filenames[i] for i in top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c906799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(len(vectors))   # Harusnya: 33\n",
    "print(vectors[0].shape)  # Harusnya: (768,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ab3db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "filenames = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd4af660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(filenames[:34])\n",
    "# Output: ['putusan1.txt', 'putusan2.txt', 'putusan3.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51b5944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir(\"data/cleaned_txt\"):\n",
    "    with open(os.path.join(\"data/cleaned_txt\", f), \"r\", encoding=\"utf-8\") as file:\n",
    "        teks = file.read().lower()\n",
    "        if \"faktur pajak\" in teks and \"pasal 39\" in teks:\n",
    "            print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce00474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Terdakwa tidak menyampaikan SPT Tahunan selama 3 tahun berturut-turut dan menyebabkan kerugian pada pendapatan negara.',\n",
       "  'ground_truth': ['putusan_01.txt']},\n",
       " {'query': 'Wajib Pajak didakwa memalsukan faktur pajak dan melanggar Pasal 39 ayat (1) huruf c UU KUP.',\n",
       "  'ground_truth': ['putusan_04.txt']},\n",
       " {'query': 'Terdakwa menyampaikan SPT Masa PPN yang tidak benar sehingga merugikan negara.',\n",
       "  'ground_truth': ['putusan_07.txt']},\n",
       " {'query': 'Tersangka menyuruh orang lain membuat faktur pajak fiktif untuk menghindari pembayaran PPN.',\n",
       "  'ground_truth': ['putusan_12.txt']},\n",
       " {'query': 'Wajib pajak diduga dengan sengaja tidak menyetorkan pajak yang telah dipotong dari pihak lain.',\n",
       "  'ground_truth': ['putusan_15.txt']}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  {\n",
    "    \"query\": \"Terdakwa tidak menyampaikan SPT Tahunan selama 3 tahun berturut-turut dan menyebabkan kerugian pada pendapatan negara.\",\n",
    "    \"ground_truth\": [\"putusan_01.txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Wajib Pajak didakwa memalsukan faktur pajak dan melanggar Pasal 39 ayat (1) huruf c UU KUP.\",\n",
    "    \"ground_truth\": [\"putusan_04.txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Terdakwa menyampaikan SPT Masa PPN yang tidak benar sehingga merugikan negara.\",\n",
    "    \"ground_truth\": [\"putusan_07.txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Tersangka menyuruh orang lain membuat faktur pajak fiktif untuk menghindari pembayaran PPN.\",\n",
    "    \"ground_truth\": [\"putusan_12.txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Wajib pajak diduga dengan sengaja tidak menyetorkan pajak yang telah dipotong dari pihak lain.\",\n",
    "    \"ground_truth\": [\"putusan_15.txt\"]\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a8fb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"pelanggaran pajak tahunan oleh wajib pajak\",\n",
    "    \"ketentuan pengampunan pajak di Indonesia\",\n",
    "    \"sanksi untuk keterlambatan pembayaran PPh\",\n",
    "    \"prosedur banding pajak penghasilan\"\n",
    "]\n",
    "filenames = [\"case(1).txt\", \"case(2).txt\", \"case(3).txt\", \"case(4).txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36505940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case (8).txt: 0.3913\n",
      "case (4).txt: 0.3798\n",
      "case (3).txt: 0.2745\n",
      "case (9).txt: 0.2676\n",
      "case (7).txt: 0.1847\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize model\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def bert_embed(text):\n",
    "    \"\"\"Returns 1D numpy array\"\"\"\n",
    "    return model.encode(text, convert_to_numpy=True).flatten()\n",
    "\n",
    "def retrieve_similar_cases(query, vectors, filenames, k=5):\n",
    "    try:\n",
    "        # 1. Validate inputs\n",
    "        if len(vectors) == 0 or len(filenames) == 0:\n",
    "            raise ValueError(\"Empty vectors or filenames list\")\n",
    "        if len(vectors) != len(filenames):\n",
    "            raise ValueError(\"Vectors and filenames length mismatch\")\n",
    "            \n",
    "        # 2. Get query embedding\n",
    "        query_vec = bert_embed(query).reshape(1, -1)\n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        # 3. Calculate similarities\n",
    "        similarities = cosine_similarity(query_vec, vectors)[0]\n",
    "        \n",
    "        # 4. Get top-k results with bounds checking\n",
    "        valid_k = min(k, len(filenames))\n",
    "        top_k = similarities.argsort()[-valid_k:][::-1]\n",
    "        \n",
    "        return [(filenames[i], similarities[i]) for i in top_k if i < len(filenames)]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieval: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "documents = [\n",
    "    # case (1).txt\n",
    "    \"Terdakwa Fadlan Djakfar didakwa sengaja membantu tindak pidana perpajakan berlanjut, yaitu menerbitkan faktur pajak berbarcode identitas Agung Kota Mandiri yang terbukti tidak berdasarkan transaksi sebenarnya, menyebabkan kerugian negara sebesar 96 juta rupiah lebih. Putusan kasasi memperbaiki denda.\",\n",
    "    \n",
    "    # case (2).txt\n",
    "    \"Terdakwa Ida Laila binti Musripin, ketua kelompok usaha Rendingan, didakwa sengaja tidak menyetorkan Pajak Pertambahan Nilai (PPN) yang dipungut dari transaksi penjualan biji kopi. Kerugian pendapatan negara dihitung 10 miliar rupiah lebih. Terdakwa menjual aset tanah untuk menutupi denda.\",\n",
    "    \n",
    "    # case (3).txt\n",
    "    \"Terdakwa Ir. Roni Wijaya, Direktur Keuangan PT Dutasari Citralaras, didakwa tindak pidana perpajakan dan tindak pidana pencucian uang. Terdakwa menginstruksikan pembelian dan penggunaan faktur pajak fiktif serta menyamarkan hasil tindak pidana untuk membeli aset properti. Putusan peninjauan kembali membatalkan putusan sebelumnya dan memerintahkan pengembalian kelebihan bayar denda.\",\n",
    "    \n",
    "    # case (4).txt\n",
    "    \"Terdakwa Dian Ekawati, Komisaris PT Cahayasurya Timur, didakwa sengaja tidak menyetorkan SPT Tahunan dan memalsukan faktur pajak. Terdakwa terbukti melakukan pengkreditan faktur pajak fiktif tanpa transaksi sebenarnya, menyebabkan kerugian negara. Putusan kasasi menguatkan putusan pengadilan negeri dengan pidana penjara dan denda.\",\n",
    "    \n",
    "    # case (5).txt\n",
    "    \"Terpidana Albert Lie, Direktur Karyaputra Lokatirta, didakwa pidana perpajakan karena menggunakan faktur pajak fiktif berdasarkan transaksi tidak sebenarnya (TBTS) yang dibeli dengan tujuan memperkecil pembayaran pajak. Putusan peninjauan kembali menolak permohonan terpidana dan menguatkan putusan sebelumnya.\",\n",
    "    \n",
    "    # case (6).txt\n",
    "    \"Terdakwa Suminto bin Priyo Utomo didakwa menyediakan dan menjual barang kena cukai (rokok) jenis Sigaret Putih Mesin (SPM) merek Luffman American Blend tanpa dilekati pita cukai. Perbuatan ini menimbulkan kerugian negara. Putusan kasasi menolak permohonan penuntut dan menguatkan pidana yang dijatuhkan.\",\n",
    "    \n",
    "    # case (7).txt\n",
    "    \"Terdakwa Mohamad Aly Shobat, Direktur Cahaya Firdaus, didakwa sengaja tidak menyetorkan Pajak Pertambahan Nilai (PPN) yang telah dipungut dari perusahaan seperti Pertamina. Putusan peninjauan kembali mengabulkan permohonan terpidana, membatalkan putusan sebelumnya, dan memerintahkan pengembalian kelebihan bayar denda karena kerugian negara telah dipulihkan.\",\n",
    "    \n",
    "    # case (8).txt\n",
    "    \"Terdakwa Tri Anis Noorbaiti, mantan General Manager Finance Accounting Shields Indonesia, didakwa tidak melaporkan SPT lengkap dan tidak menyetorkan pajak yang dipotong/dipungut (PPN dan PPh Pasal 23 rekanan). Putusan peninjauan kembali menguatkan bahwa terpidana terbukti bersalah.\",\n",
    "    \n",
    "    # case (9).txt\n",
    "    \"Terdakwa Ihmar, Direktur Andoyo Tofan Nugraha Abadi, didakwa sengaja menerbitkan faktur pajak berdasarkan transaksi tidak sebenarnya (TBTS) dan mengkreditkan SPT PPN fiktif, yang menyebabkan kerugian negara. Putusan kasasi menolak permohonan terpidana dan menguatkan putusan sebelumnya.\",\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    \"case (1).txt\",\n",
    "    \"case (2).txt\",\n",
    "    \"case (3).txt\",\n",
    "    \"case (4).txt\",\n",
    "    \"case (5).txt\",\n",
    "    \"case (6).txt\",\n",
    "    \"case (7).txt\",\n",
    "    \"case (8).txt\",\n",
    "    \"case (9).txt\"\n",
    "]\n",
    "# Precompute vectors\n",
    "vectors = [bert_embed(doc) for doc in documents]\n",
    "\n",
    "# Test query\n",
    "query = \"Pelanggaran SPT Tahunan\"\n",
    "results = retrieve_similar_cases(query, vectors, filenames)\n",
    "\n",
    "if not results:\n",
    "    print(\"⚠️ No results returned. Check your inputs.\")\n",
    "else:\n",
    "    for filename, score in results:\n",
    "        print(f\"{filename}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cbd36755",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = [3, 7, 10, 4, 19]  # indeks file teratas hasil similarity\n",
    "filenames = [...]           # nama-nama file .txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a844c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambil_teks_file(nama_file, folder=\"data/cleaned_txt\"):\n",
    "    with open(os.path.join(folder, nama_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "31a1a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape vectors: 9\n",
      "Shape filenames: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape vectors:\", len(vectors))\n",
    "print(\"Shape filenames:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b8ae42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Contoh split vektor dan nama file\n",
    "X_train, X_test, filenames_train, filenames_test = train_test_split(vectors, filenames, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26d8d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ queries.json berhasil dibuat.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Buat folder eval jika belum ada\n",
    "os.makedirs(\"data/eval\", exist_ok=True)\n",
    "\n",
    "# Isi queries dan ground_truth (silakan sesuaikan)\n",
    "queries = [\n",
    "  {\n",
    "    \"query\": \"Terdakwa tidak menyampaikan Surat Pemberitahuan (SPT) Tahunan Pajak Penghasilan secara sengaja, yang mengakibatkan kerugian pendapatan negara.\",\n",
    "    \"ground_truth\": [\"case (24).txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Terdakwa mengkreditkan faktur pajak fiktif tanpa transaksi sebenarnya, melanggar UU Ketentuan Umum dan Tata Cara Perpajakan.\",\n",
    "    \"ground_truth\": [\"case (30).txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Terdakwa menyampaikan faktur pajak tidak sah untuk mengurangi pajak yang terutang, menyebabkan kerugian negara.\",\n",
    "    \"ground_truth\": [\"case (4).txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Terdakwa terbukti melakukan pelanggaran Pasal 39 UU KUP dan Pasal 3 UU TPPU karena menyembunyikan aset dari penghasilan tak sah.\",\n",
    "    \"ground_truth\": [\"case (3).txt\"]\n",
    "  },\n",
    "  {\n",
    "    \"query\": \"Terdakwa tidak menyetorkan PPN yang telah dipungut kepada negara, berdasarkan pasal 39 ayat 1 huruf i UU KUP.\",\n",
    "    \"ground_truth\": [\"case (33).txt\"]\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "# Simpan ke JSON\n",
    "with open(\"data/eval/queries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(queries, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ queries.json berhasil dibuat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "51f20af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(eval_queries, vectors, filenames, k=5):\n",
    "    from sklearn.metrics import precision_score\n",
    "\n",
    "    total = 0\n",
    "    matched = 0\n",
    "    for q in eval_queries:\n",
    "        pred = retrieve(q[\"query\"], vectors, filenames, k=k)\n",
    "        if any(p in q[\"ground_truth\"] for p in pred):\n",
    "            matched += 1\n",
    "        total += 1\n",
    "    print(f\"Accuracy top-{k}: {matched}/{total} = {matched/total:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "242c2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy top-5: 2/5 = 0.40\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/eval/queries.json\", encoding=\"utf-8\") as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "evaluate_retrieval(queries, vectors, filenames, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c35a4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah dokumen: 33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = \"data/cleaned_txt\"\n",
    "docs = []\n",
    "filenames = []\n",
    "\n",
    "for fname in sorted(os.listdir(folder)):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            teks = f.read()\n",
    "        docs.append(teks)\n",
    "        filenames.append(fname)\n",
    "\n",
    "print(f\"Jumlah dokumen: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11b4c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# 1. Persiapan stop words\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()\n",
    "\n",
    "# 2. Inisialisasi vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words=stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,  # Abaikan terms yang muncul di kurang dari 3 dokumen\n",
    "    max_df=0.8  # Abaikan terms yang muncul di lebih dari 80% dokumen\n",
    ")\n",
    "\n",
    "# 3. Fit dan transform\n",
    "X_tfidf = vectorizer.fit_transform(docs)  # Pastikan 'docs' berisi teks dokumen\n",
    "\n",
    "# 4. Dapatkan fitur (kata-kata)\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2e4aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def retrieve_tfidf(query, k=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, X_tfidf).flatten()\n",
    "    top_k = sims.argsort()[-k:][::-1]\n",
    "    return [(filenames[i], sims[i]) for i in top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fcb3d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case (24).txt (skor: 0.0879)\n",
      "case (25).txt (skor: 0.0419)\n",
      "case (10).txt (skor: 0.0417)\n",
      "case (15).txt (skor: 0.0405)\n",
      "case (19).txt (skor: 0.0376)\n"
     ]
    }
   ],
   "source": [
    "query = \"Terdakwa tidak menyampaikan SPT Tahunan selama 3 tahun\"\n",
    "hasil = retrieve_tfidf(query)\n",
    "\n",
    "for fname, skor in hasil:\n",
    "    print(f\"{fname} (skor: {skor:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d204c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/processed/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(\"data/processed/tfidf_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_tfidf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "16b4a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def evaluate_retrieval_tfidf(queries_json_path, k=5):\n",
    "    with open(queries_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        queries = json.load(f)\n",
    "\n",
    "    total = len(queries)\n",
    "    match = 0\n",
    "\n",
    "    for q in queries:\n",
    "        pred = retrieve_tfidf(q[\"query\"], k=k)\n",
    "        pred_files = [f for f, _ in pred]\n",
    "\n",
    "        if any(gt in pred_files for gt in q[\"ground_truth\"]):\n",
    "            match += 1\n",
    "\n",
    "        print(f\"\\n🔍 Query: {q['query']}\")\n",
    "        print(f\"🎯 Ground Truth: {q['ground_truth']}\")\n",
    "        print(f\"🔁 Prediksi Top-{k}: {pred_files}\")\n",
    "\n",
    "    accuracy = match / total\n",
    "    print(f\"\\n✅ Accuracy@{k}: {match}/{total} = {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "29fd25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Terdakwa tidak menyampaikan Surat Pemberitahuan (SPT) Tahunan Pajak Penghasilan secara sengaja, yang mengakibatkan kerugian pendapatan negara.\n",
      "Ground Truth: ['case (24).txt']\n",
      "Top-5 Results: []\n",
      "\n",
      "Query: Terdakwa mengkreditkan faktur pajak fiktif tanpa transaksi sebenarnya, melanggar UU Ketentuan Umum dan Tata Cara Perpajakan.\n",
      "Ground Truth: ['case (30).txt']\n",
      "Top-5 Results: []\n",
      "\n",
      "Query: Terdakwa menyampaikan faktur pajak tidak sah untuk mengurangi pajak yang terutang, menyebabkan kerugian negara.\n",
      "Ground Truth: ['case (4).txt']\n",
      "Top-5 Results: []\n",
      "\n",
      "Query: Terdakwa terbukti melakukan pelanggaran Pasal 39 UU KUP dan Pasal 3 UU TPPU karena menyembunyikan aset dari penghasilan tak sah.\n",
      "Ground Truth: ['case (3).txt']\n",
      "Top-5 Results: []\n",
      "\n",
      "Query: Terdakwa tidak menyetorkan PPN yang telah dipungut kepada negara, berdasarkan pasal 39 ayat 1 huruf i UU KUP.\n",
      "Ground Truth: ['case (33).txt']\n",
      "Top-5 Results: []\n",
      "\n",
      "Accuracy@5: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. Initialize and fit TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = vectorizer.fit_transform(documents)  # documents = list of your text docs\n",
    "filenames = [...]  # must match documents exactly\n",
    "\n",
    "# 2. Fixed retrieve function\n",
    "def retrieve_tfidf(query, k=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, X_tfidf).flatten()\n",
    "    \n",
    "    # Handle case when k > number of documents\n",
    "    k = min(k, len(filenames))\n",
    "    \n",
    "    top_k = sims.argsort()[-k:][::-1]\n",
    "    return [(filenames[i], sims[i]) for i in top_k if i < len(filenames)]\n",
    "\n",
    "# 3. Fixed evaluation function\n",
    "def evaluate_retrieval_tfidf(queries_json_path, k=5):\n",
    "    with open(queries_json_path, \"r\") as f:\n",
    "        queries = json.load(f)\n",
    "    \n",
    "    total = len(queries)\n",
    "    match = 0\n",
    "    \n",
    "    for q in queries:\n",
    "        try:\n",
    "            pred = retrieve_tfidf(q[\"query\"], k=k)\n",
    "            pred_files = [f for f, _ in pred]\n",
    "            \n",
    "            if any(gt in pred_files for gt in q[\"ground_truth\"]):\n",
    "                match += 1\n",
    "                \n",
    "            print(f\"\\nQuery: {q['query']}\")\n",
    "            print(f\"Ground Truth: {q['ground_truth']}\")\n",
    "            print(f\"Top-{k} Results: {pred_files}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query: {q['query']} - {str(e)}\")\n",
    "    \n",
    "    accuracy = match / total\n",
    "    print(f\"\\nAccuracy@{k}: {accuracy:.2%}\")\n",
    "\n",
    "# 4. Run evaluation\n",
    "evaluate_retrieval_tfidf(\"data/eval/queries.json\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fe707b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name indobenchmark/indobert-base-p2. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# 1. Improved Legal-Specific Preprocessing\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Legal-specific preprocessing\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'pasal \\d+', ' ', text)  # Normalize law articles\n",
    "    text = re.sub(r'uu [a-z]+', ' ', text)  # Normalize law references\n",
    "    text = stemmer.stem(text)\n",
    "    return text\n",
    "\n",
    "# 2. Enhanced BERT Model (Legal-Tuned)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('indobenchmark/indobert-base-p2')  # Indonesian legal-optimized\n",
    "\n",
    "# 3. Improved Retrieval Function\n",
    "def retrieve_legal_case(query, k=5):\n",
    "    # Legal-specific query expansion\n",
    "    expanded_query = f\"{query} hukum pajak undang-undang perpajakan\"\n",
    "    \n",
    "    # Preprocess and encode\n",
    "    processed_query = preprocess_text(expanded_query)\n",
    "    query_vec = model.encode(processed_query, convert_to_tensor=True)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sims = cosine_similarity(query_vec.unsqueeze(0), bert_vectors)[0]\n",
    "    top_k = sims.argsort()[-k:][::-1]\n",
    "    \n",
    "    return [filenames[i] for i in top_k if sims[i] > 0.3]  # Threshold\n",
    "\n",
    "# 4. Enhanced Evaluation\n",
    "def evaluate_legal_retrieval(queries):\n",
    "    results = []\n",
    "    for q in queries:\n",
    "        pred = retrieve_legal_case(q[\"query\"])\n",
    "        is_match = any(gt in pred for gt in q[\"ground_truth\"])\n",
    "        \n",
    "        # Legal-specific analysis\n",
    "        legal_articles = extract_legal_articles(q[\"query\"])\n",
    "        results.append({\n",
    "            \"query\": q[\"query\"],\n",
    "            \"articles\": legal_articles,\n",
    "            \"predicted\": pred,\n",
    "            \"correct\": is_match\n",
    "        })\n",
    "    \n",
    "    accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
    "    return accuracy, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7acabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval_bert(queries_json_path, k=5):\n",
    "    with open(queries_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        queries = json.load(f)\n",
    "\n",
    "    total = len(queries)\n",
    "    match = 0\n",
    "\n",
    "    for q in queries:\n",
    "        pred = retrieve(q[\"query\"], vectors, filenames, k=k)  # IndoBERT\n",
    "        if any(gt in pred for gt in q[\"ground_truth\"]):\n",
    "            match += 1\n",
    "\n",
    "        print(f\"\\n🔍 Query: {q['query']}\")\n",
    "        print(f\"🎯 Ground Truth: {q['ground_truth']}\")\n",
    "        print(f\"🔁 Prediksi Top-{k}: {pred}\")\n",
    "\n",
    "    accuracy = match / total\n",
    "    print(f\"\\n✅ Accuracy@{k}: {match}/{total} = {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dbf94778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Query: Terdakwa tidak menyampaikan Surat Pemberitahuan (SPT) Tahunan Pajak Penghasilan secara sengaja, yang mengakibatkan kerugian pendapatan negara.\n",
      "🎯 Ground Truth: ['case (24).txt']\n",
      "🔁 Prediksi Top-5: ['case (4).txt', 'case (5).txt', 'case (1).txt', 'case (7).txt', 'case (9).txt']\n",
      "\n",
      "🔍 Query: Terdakwa mengkreditkan faktur pajak fiktif tanpa transaksi sebenarnya, melanggar UU Ketentuan Umum dan Tata Cara Perpajakan.\n",
      "🎯 Ground Truth: ['case (30).txt']\n",
      "🔁 Prediksi Top-5: ['case (5).txt', 'case (4).txt', 'case (3).txt', 'case (9).txt', 'case (1).txt']\n",
      "\n",
      "🔍 Query: Terdakwa menyampaikan faktur pajak tidak sah untuk mengurangi pajak yang terutang, menyebabkan kerugian negara.\n",
      "🎯 Ground Truth: ['case (4).txt']\n",
      "🔁 Prediksi Top-5: ['case (5).txt', 'case (1).txt', 'case (4).txt', 'case (9).txt', 'case (3).txt']\n",
      "\n",
      "🔍 Query: Terdakwa terbukti melakukan pelanggaran Pasal 39 UU KUP dan Pasal 3 UU TPPU karena menyembunyikan aset dari penghasilan tak sah.\n",
      "🎯 Ground Truth: ['case (3).txt']\n",
      "🔁 Prediksi Top-5: ['case (3).txt', 'case (4).txt', 'case (5).txt', 'case (9).txt', 'case (7).txt']\n",
      "\n",
      "🔍 Query: Terdakwa tidak menyetorkan PPN yang telah dipungut kepada negara, berdasarkan pasal 39 ayat 1 huruf i UU KUP.\n",
      "🎯 Ground Truth: ['case (33).txt']\n",
      "🔁 Prediksi Top-5: ['case (7).txt', 'case (4).txt', 'case (9).txt', 'case (8).txt', 'case (2).txt']\n",
      "\n",
      "✅ Accuracy@5: 2/5 = 40.00%\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. Initialize BERT model\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 2. Define retrieve function\n",
    "def retrieve(query, vectors, filenames, k=5):\n",
    "    query_vec = model.encode(query)\n",
    "    similarities = cosine_similarity([query_vec], vectors)[0]\n",
    "    top_k_idx = similarities.argsort()[-k:][::-1]\n",
    "    return [filenames[i] for i in top_k_idx]\n",
    "\n",
    "# 3. Modified evaluation function to accept vectors and filenames\n",
    "def evaluate_retrieval_bert(queries_json_path, vectors, filenames, k=5):\n",
    "    with open(queries_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        queries = json.load(f)\n",
    "\n",
    "    total = len(queries)\n",
    "    match = 0\n",
    "\n",
    "    for q in queries:\n",
    "        pred = retrieve(q[\"query\"], vectors, filenames, k=k)\n",
    "        if any(gt in pred for gt in q[\"ground_truth\"]):\n",
    "            match += 1\n",
    "\n",
    "        print(f\"\\n🔍 Query: {q['query']}\")\n",
    "        print(f\"🎯 Ground Truth: {q['ground_truth']}\")\n",
    "        print(f\"🔁 Prediksi Top-{k}: {pred}\")\n",
    "\n",
    "    accuracy = match / total\n",
    "    print(f\"\\n✅ Accuracy@{k}: {match}/{total} = {accuracy:.2%}\")\n",
    "\n",
    "documents = [\n",
    "    # case (1).txt\n",
    "    \"Terdakwa Fadlan Djakfar didakwa sengaja membantu tindak pidana perpajakan berlanjut, yaitu menerbitkan faktur pajak berbarcode identitas Agung Kota Mandiri yang terbukti tidak berdasarkan transaksi sebenarnya, menyebabkan kerugian negara sebesar 96 juta rupiah lebih. Putusan kasasi memperbaiki denda.\",\n",
    "    \n",
    "    # case (2).txt\n",
    "    \"Terdakwa Ida Laila binti Musripin, ketua kelompok usaha Rendingan, didakwa sengaja tidak menyetorkan Pajak Pertambahan Nilai (PPN) yang dipungut dari transaksi penjualan biji kopi. Kerugian pendapatan negara dihitung 10 miliar rupiah lebih. Terdakwa menjual aset tanah untuk menutupi denda.\",\n",
    "    \n",
    "    # case (3).txt\n",
    "    \"Terdakwa Ir. Roni Wijaya, Direktur Keuangan PT Dutasari Citralaras, didakwa tindak pidana perpajakan dan tindak pidana pencucian uang. Terdakwa menginstruksikan pembelian dan penggunaan faktur pajak fiktif serta menyamarkan hasil tindak pidana untuk membeli aset properti. Putusan peninjauan kembali membatalkan putusan sebelumnya dan memerintahkan pengembalian kelebihan bayar denda.\",\n",
    "    \n",
    "    # case (4).txt\n",
    "    \"Terdakwa Dian Ekawati, Komisaris PT Cahayasurya Timur, didakwa sengaja tidak menyetorkan SPT Tahunan dan memalsukan faktur pajak. Terdakwa terbukti melakukan pengkreditan faktur pajak fiktif tanpa transaksi sebenarnya, menyebabkan kerugian negara. Putusan kasasi menguatkan putusan pengadilan negeri dengan pidana penjara dan denda.\",\n",
    "    \n",
    "    # case (5).txt\n",
    "    \"Terpidana Albert Lie, Direktur Karyaputra Lokatirta, didakwa pidana perpajakan karena menggunakan faktur pajak fiktif berdasarkan transaksi tidak sebenarnya (TBTS) yang dibeli dengan tujuan memperkecil pembayaran pajak. Putusan peninjauan kembali menolak permohonan terpidana dan menguatkan putusan sebelumnya.\",\n",
    "    \n",
    "    # case (6).txt\n",
    "    \"Terdakwa Suminto bin Priyo Utomo didakwa menyediakan dan menjual barang kena cukai (rokok) jenis Sigaret Putih Mesin (SPM) merek Luffman American Blend tanpa dilekati pita cukai. Perbuatan ini menimbulkan kerugian negara. Putusan kasasi menolak permohonan penuntut dan menguatkan pidana yang dijatuhkan.\",\n",
    "    \n",
    "    # case (7).txt\n",
    "    \"Terdakwa Mohamad Aly Shobat, Direktur Cahaya Firdaus, didakwa sengaja tidak menyetorkan Pajak Pertambahan Nilai (PPN) yang telah dipungut dari perusahaan seperti Pertamina. Putusan peninjauan kembali mengabulkan permohonan terpidana, membatalkan putusan sebelumnya, dan memerintahkan pengembalian kelebihan bayar denda karena kerugian negara telah dipulihkan.\",\n",
    "    \n",
    "    # case (8).txt\n",
    "    \"Terdakwa Tri Anis Noorbaiti, mantan General Manager Finance Accounting Shields Indonesia, didakwa tidak melaporkan SPT lengkap dan tidak menyetorkan pajak yang dipotong/dipungut (PPN dan PPh Pasal 23 rekanan). Putusan peninjauan kembali menguatkan bahwa terpidana terbukti bersalah.\",\n",
    "    \n",
    "    # case (9).txt\n",
    "    \"Terdakwa Ihmar, Direktur Andoyo Tofan Nugraha Abadi, didakwa sengaja menerbitkan faktur pajak berdasarkan transaksi tidak sebenarnya (TBTS) dan mengkreditkan SPT PPN fiktif, yang menyebabkan kerugian negara. Putusan kasasi menolak permohonan terpidana dan menguatkan putusan sebelumnya.\",\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    \"case (1).txt\",\n",
    "    \"case (2).txt\",\n",
    "    \"case (3).txt\",\n",
    "    \"case (4).txt\",\n",
    "    \"case (5).txt\",\n",
    "    \"case (6).txt\",\n",
    "    \"case (7).txt\",\n",
    "    \"case (8).txt\",\n",
    "    \"case (9).txt\"\n",
    "]\n",
    "\n",
    "# 5. Precompute document embeddings\n",
    "vectors = model.encode(documents)\n",
    "\n",
    "# 6. Run evaluation (make sure queries.json exists)\n",
    "evaluate_retrieval_bert(\n",
    "    queries_json_path=\"data/eval/queries.json\",\n",
    "    vectors=vectors,\n",
    "    filenames=filenames,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b14b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f36d5b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation Results (BERT)\n",
      "✅ Accuracy: 100.00%\n",
      "\n",
      "Query 1: faktur pajak fiktif\n",
      "Ground Truth: ['case (1).txt', 'case (3).txt', 'case (4).txt', 'case (5).txt', 'case (9).txt']\n",
      "Top Results: ['case (5).txt', 'case (4).txt', 'case (1).txt', 'case (3).txt', 'case (9).txt']\n",
      "Match: ✔️\n",
      "\n",
      "Query 2: tidak menyetorkan PPN\n",
      "Ground Truth: ['case (2).txt', 'case (7).txt', 'case (8).txt']\n",
      "Top Results: ['case (7).txt', 'case (8).txt', 'case (4).txt', 'case (9).txt', 'case (2).txt']\n",
      "Match: ✔️\n",
      "\n",
      "Query 3: tidak menyampaikan SPT Tahunan\n",
      "Ground Truth: ['case (1).txt', 'case (4).txt', 'case (8).txt']\n",
      "Top Results: ['case (8).txt', 'case (4).txt', 'case (9).txt', 'case (5).txt', 'case (3).txt']\n",
      "Match: ✔️\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Initialize model\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 2. Prepare documents and filenames (your existing data)\n",
    "documents = [\n",
    "    # case (1).txt\n",
    "    \"Terdakwa Fadlan Djakfar didakwa sengaja membantu tindak pidana perpajakan berlanjut, yaitu menerbitkan faktur pajak berbarcode identitas Agung Kota Mandiri yang terbukti tidak berdasarkan transaksi sebenarnya, menyebabkan kerugian negara sebesar 96 juta rupiah lebih. Putusan kasasi memperbaiki denda.\",\n",
    "    \n",
    "    # case (2).txt\n",
    "    \"Terdakwa Ida Laila binti Musripin, ketua kelompok usaha Rendingan, didakwa sengaja tidak menyetorkan Pajak Pertambahan Nilai (PPN) yang dipungut dari transaksi penjualan biji kopi. Kerugian pendapatan negara dihitung 10 miliar rupiah lebih. Terdakwa menjual aset tanah untuk menutupi denda.\",\n",
    "    \n",
    "    # case (3).txt\n",
    "    \"Terdakwa Ir. Roni Wijaya, Direktur Keuangan PT Dutasari Citralaras, didakwa tindak pidana perpajakan dan tindak pidana pencucian uang. Terdakwa menginstruksikan pembelian dan penggunaan faktur pajak fiktif serta menyamarkan hasil tindak pidana untuk membeli aset properti. Putusan peninjauan kembali membatalkan putusan sebelumnya dan memerintahkan pengembalian kelebihan bayar denda.\",\n",
    "    \n",
    "    # case (4).txt\n",
    "    \"Terdakwa Dian Ekawati, Komisaris PT Cahayasurya Timur, didakwa sengaja tidak menyetorkan SPT Tahunan dan memalsukan faktur pajak. Terdakwa terbukti melakukan pengkreditan faktur pajak fiktif tanpa transaksi sebenarnya, menyebabkan kerugian negara. Putusan kasasi menguatkan putusan pengadilan negeri dengan pidana penjara dan denda.\",\n",
    "    \n",
    "    # case (5).txt\n",
    "    \"Terpidana Albert Lie, Direktur Karyaputra Lokatirta, didakwa pidana perpajakan karena menggunakan faktur pajak fiktif berdasarkan transaksi tidak sebenarnya (TBTS) yang dibeli dengan tujuan memperkecil pembayaran pajak. Putusan peninjauan kembali menolak permohonan terpidana dan menguatkan putusan sebelumnya.\",\n",
    "    \n",
    "    # case (6).txt\n",
    "    \"Terdakwa Suminto bin Priyo Utomo didakwa menyediakan dan menjual barang kena cukai (rokok) jenis Sigaret Putih Mesin (SPM) merek Luffman American Blend tanpa dilekati pita cukai. Perbuatan ini menimbulkan kerugian negara. Putusan kasasi menolak permohonan penuntut dan menguatkan pidana yang dijatuhkan.\",\n",
    "    \n",
    "    # case (7).txt\n",
    "    \"Terdakwa Mohamad Aly Shobat, Direktur Cahaya Firdaus, didakwa sengaja tidak menyetorkan Pajak Pertambahan Nilai (PPN) yang telah dipungut dari perusahaan seperti Pertamina. Putusan peninjauan kembali mengabulkan permohonan terpidana, membatalkan putusan sebelumnya, dan memerintahkan pengembalian kelebihan bayar denda karena kerugian negara telah dipulihkan.\",\n",
    "    \n",
    "    # case (8).txt\n",
    "    \"Terdakwa Tri Anis Noorbaiti, mantan General Manager Finance Accounting Shields Indonesia, didakwa tidak melaporkan SPT lengkap dan tidak menyetorkan pajak yang dipotong/dipungut (PPN dan PPh Pasal 23 rekanan). Putusan peninjauan kembali menguatkan bahwa terpidana terbukti bersalah.\",\n",
    "    \n",
    "    # case (9).txt\n",
    "    \"Terdakwa Ihmar, Direktur Andoyo Tofan Nugraha Abadi, didakwa sengaja menerbitkan faktur pajak berdasarkan transaksi tidak sebenarnya (TBTS) dan mengkreditkan SPT PPN fiktif, yang menyebabkan kerugian negara. Putusan kasasi menolak permohonan terpidana dan menguatkan putusan sebelumnya.\",\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    \"case (1).txt\",\n",
    "    \"case (2).txt\", \n",
    "    \"case (3).txt\",\n",
    "    \"case (4).txt\",\n",
    "    \"case (5).txt\",\n",
    "    \"case (6).txt\",\n",
    "    \"case (7).txt\",\n",
    "    \"case (8).txt\",\n",
    "    \"case (9).txt\"\n",
    "]\n",
    "\n",
    "# 3. Precompute document embeddings\n",
    "bert_vectors = model.encode(documents)\n",
    "\n",
    "def retrieve_bert(query, k=5):\n",
    "    query_vec = model.encode(query).reshape(1, -1)\n",
    "    sims = cosine_similarity(query_vec, bert_vectors)[0]\n",
    "    top_k = sims.argsort()[-k:][::-1]\n",
    "    return [filenames[i] for i in top_k]\n",
    "\n",
    "# 4. Fixed evaluation function\n",
    "def evaluate_retrieval(retrieve_fn, queries, k=5):\n",
    "    total = len(queries)\n",
    "    match = 0\n",
    "    details = []\n",
    "    \n",
    "    for q in queries:\n",
    "        pred = retrieve_fn(q[\"query\"], k)\n",
    "        \n",
    "        # Convert ground truth to match your filename format\n",
    "        gt_files = [f\"case ({gt}).txt\" if isinstance(gt, int) else gt for gt in q[\"ground_truth\"]]\n",
    "        \n",
    "        is_match = any(gt in pred for gt in gt_files)\n",
    "        if is_match:\n",
    "            match += 1\n",
    "            \n",
    "        details.append({\n",
    "            \"query\": q[\"query\"],\n",
    "            \"ground_truth\": gt_files,\n",
    "            \"predicted\": pred,\n",
    "            \"matched\": is_match\n",
    "        })\n",
    "    \n",
    "    accuracy = match / total if total > 0 else 0.0\n",
    "    return accuracy, details\n",
    "\n",
    "# 5. Proper test queries with matching ground truth\n",
    "queries = [\n",
    "    {\n",
    "        \"query\": \"faktur pajak fiktif\",\n",
    "        \"ground_truth\": [1, 3, 4, 5, 9]  # Cases that mention fake invoices\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"tidak menyetorkan PPN\",\n",
    "        \"ground_truth\": [2, 7, 8]  # Cases about unpaid VAT\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"tidak menyampaikan SPT Tahunan\",\n",
    "        \"ground_truth\": [1, 4, 8]  # Cases about unreported tax returns\n",
    "    }\n",
    "]\n",
    "\n",
    "# 6. Run evaluation\n",
    "accuracy, results = evaluate_retrieval(retrieve_bert, queries, k=5)\n",
    "\n",
    "print(f\"\\n🔍 Evaluation Results (BERT)\")\n",
    "print(f\"✅ Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Query {i+1}: {result['query']}\")\n",
    "    print(f\"Ground Truth: {result['ground_truth']}\")\n",
    "    print(f\"Top Results: {result['predicted']}\")\n",
    "    print(f\"Match: {'✔️' if result['matched'] else '❌'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da827e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAx6ElEQVR4nO3dCdzNdf7//5d9i6vsS0QrIoy90CZapWWSpkhNTRtKM3VpIRSSiWYoQ6WZacSYouUrI8pQaZSrQkVJuiTryBKFOL/b8/3/f87tnHOdi3Ou7Vzn7XG/3c6N87nO8jmfs3yen9d7+ZQIhUIhAwAA8ETJVK8AAABAQSLcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdygWGnYsKFdeumlVpycc8457hJYt26dlShRwl544QU72ug167V/9NFHlk5i30OknxtvvNH9PgCJINwg4R1acClfvrydeuqpdtddd9nmzZtTvXooQNdcc417j++//347mjzyyCNRn/HcLkFA0o42t9vMnTv3sM+1cOFCd7t//etfh/2O1a1b17p3725/+tOfbPfu3Umt86RJkyyVittBitYndvuecsop9oc//MG2b9+e1Gdh06ZNUQc5waVkyZJWtWpVu+iii2zJkiVx39fcLoS2gle6EB4Tnho+fLg1atTIfv75Z3v33XftmWeesTlz5tjKlSutYsWKdrQ44YQT7KeffrIyZcqYT3bt2mWvv/66+6F96aWXbPTo0e6H1wfz5s077N+vvPJKO/nkk8PXf/zxR7v99tvtiiuucH8L1KpVK/z/cuXK2bPPPpvjsVq0aJHv79iBAwfcTlRB6O6777Ynn3zSXnvtNTvjjDNy3Effw2OOOSZqWfv27fO8Dr5q2bKl3Xvvve7/+g1btmyZjR8/3v7zn//Y0qVLE9qucuyxx0Zd7927t1188cV28OBB+/LLL+3pp5+2c8891z788EPr0qWL/f3vf4+6/W9/+1tr166d3XrrreFl8Z4H+UO4QcJ0RNKmTZvwF7RatWruR/fVV191X/D82Lt3b9oEpODIzzcvv/yy+4F+/vnn7bzzzrNFixbZ2WefXeTrsWfPHqtUqVKBPmbZsmUP+3eFhsjgsG3bNhdutOz666+Pe5/SpUvn+reC+I7J4MGD7e2333ZVkB49etgXX3xhFSpUiLrP1VdfbdWrVy/Q9fBRvXr1ot4v/YYpVIwdO9a++uorV8nJy3b91a9+FfW4nTt3du+jwpGCzoknnhh1+9tuu80tK+jPDqLRLIU80w5Qvvnmm/CyF1980Vq3bu1+gFWivfbaa239+vVR91Npv1mzZu7ISUc2CjUPPPBAjiNtHWkpRDRt2tReeeWVqL+rlPz73//emjdv7n6gqlSp4n5QPv3007hNAP/85z/tscces+OPP9495vnnn29r1qzJ8ZomT55sJ510klt/HV0tXrw4x23i9blRM4XWY8OGDdazZ0/3/xo1arh1VGCI9L///c9uuOEGt846Cuzbt69b79jHXL58uXtc/RBqnWvXrm033XSTu3+8Mrpej26vx8zIyLB+/fq50Jiof/zjH3bBBRe4o84mTZq464n44Ycf3LbStl29enV4m+vfRLfb119/7Y5+K1eubL/5zW/c37Ttf/3rX1uDBg1claR+/fp2zz33uKpZJFU49Fr1/LpdnTp17PLLL3fP50OfG33PHn74Yfv222/d9yu/FJRid7iBjh07RoWrt956yzp16uQ+U3qfTjvttBzf1UQE772CRPAd03vVtm1bV+GINXv2bPcboc+9/p01a1auQVjVGH029HhaPz1HKBRKaL30nQqCakFRuBF9ppE6VG6QZ8GXVxUcUXjQj7D6beioaOvWrfbnP//ZBZiPP/44qpyrHbTCiMKPjmAiy/06iurVq5c7wtGOf+rUqW4np74M2vnK2rVr3Q+glquMr74/f/nLX1yl4fPPP3f9FSKpiUVt4gobO3futDFjxrid6H//+9/wbZ577jn73e9+Z2eeeaZrCtBz6GhZIU0/nkeiEKM+EmoS0A/s/Pnz7Y9//KP7IVcVQA4dOmSXXXaZK4NrWePGjV3lS68zlnYsWgftuPUj/Nlnn7kdg/794IMPcjQZabtrW4waNcqysrJck0nNmjXt8ccfP+K6f//99/bOO+/YX//6V3ddlbhx48bZhAkTDlv1UIVD74nCpsr7eq0bN260ZPzyyy9uu2knqu0WVPBmzpzpwpm2kz5j2mb6PH333Xfub4GrrrrKbZP+/fu7JrUtW7a4bZednV3ofRn0+iOpqVLBsqApDCtUKPTfcsstUX+L7TNSqlQpO+6443J9LH23+vTp40KFwkVA4UmfqyeeeMJd1zZVEFL1Ss1lCg8K0O+9916eX8e0adNc/yF9z/T51fdQzX76nAfNvHqNek91UKPPsn4rgvAaSQFG3099bm+++WZ3MPTvf//b9aPRQYY+v5HU1Be8X2qW0m+SKs/6fdL3Jlbsdg1CUGyzVKwgVB/uPUARCAFHMHXqVB0GhebPnx/aunVraP369aHp06eHqlWrFqpQoULou+++C61bty5UqlSp0GOPPRZ13xUrVoRKly4dtfzss892jzdp0qQcz3XCCSe4v7388svhZTt37gzVqVMn1KpVq/Cyn3/+OXTw4MGo+37zzTehcuXKhYYPHx5e9s4777jHa9KkSWjfvn3h5U899ZRbrvWT/fv3h2rWrBlq2bJl1O0mT57sbqd1jnweLdN2CfTt29cti3xu0Tq3bt06fF2vS7cbP358eJlex3nnnZfjMffu3Ztj+7z00kvudosWLQovGzp0qFt20003Rd32iiuucO9RIsaOHevey127drnrX375pXvMWbNmxf0sfPjhh6GNGzeGTj/99NCJJ57o3v/Yba5/Ix1uu2VmZuZYp3ivf9SoUaESJUqEvv32W3f9hx9+cPd/4oknDvv69P5FvodHos+5HlfbNp5gvWMviTxHsH1mzpwZd7vmJiMjI+o7ELzvsRd9hw5H3yd9T+69996o5WPGjInatuPGjXOPp22RLK3DJZdckuO91+dx+/bt4eWvvvqqW/7666+Hl+k7qO/7jh07wsvmzZuX47XNnj3bLXv00Uejnvvqq692r2PNmjVR6xNvW5111lmhbdu2Rd0/t+2qy2mnnZbjNQ0bNsxto02bNoUWL14catu2bY73N1KlSpXc5weFi2YpJKxr166uqUVVDFVcVKZWuVht2Wo2UlVC1QMdHQUXVRzUlq2jq0g6CtTRWDyquqgjZ0DNNzrS1JFWMFJB91clJqiY6OguKJurahFLzxVZgQhKxzpiFA1t1hG/qkWRt1OzSTJH4rp/JD1P8Byi6pOOUCOPvvU67rzzzhyPFdm3Qkea2p4dOnRw1+O9xnjPre2ijsJHoiaoSy65xDULid4zNS/m1jSl6omqZDoaVt8cdbLOj6CyldvrV/ODXr+qajpi12chuI3eLzWBqXmsKKnJRBWiyIsqdYVFn+94o6bUVypyHY7UnBg04aqpNrL5ZsaMGe7zpWZACSoUqizqu10QVDWKrGjEfg9V9fvkk09cJTPye6fqoCo5kTSYQVWqAQMGRC1XM5Ve15tvvhm1XBXVYBu98cYbrtKs6pSqP7FNnfG2qy6qIscaOnSo+13Ub51ej/pF6XOgPjtIHZqlkLCJEye6IeAqzaoZSUEiCBhqStIPSmynvEDsyCIFotyaOzRqJbbJRc8blHz1I6If26eeesp12FOfn8h+LUEzWaTgBzsQ/MAGO0SV5CV2/bXeufVPiLez049c7PNE7nT1POoTEtt5OnKkTmRZfNiwYTZ9+nQXvCKpaS2Z16gdWm70Y6ywoAAZ2Q9JfVT0niscxd5fzST6HOi+Qb+FvNLjxDY5iJqVhgwZ4kYJxQaX4PUr5KrZTTs0fSa1c1ZTil5LftfrSLRjVeDPTRDEA9pZx3YGToZGcKmZMZaaVZLtUKyQoWZdDVlWYFQTczB6KPI2atpUE3NmZqbrp6YmJO20g+99svL6PZTYAxfdVgdCQSAPqL9Y5GMFtI0i3y+FeT2mXo9ep5o187JdNepJzeM6AFHnbw3dj+1nh6JHuEHC1Gk0srNhJIUNBRIdLelHP1bsUMf8/MjLyJEjXf8edbAdMWKE6xejH1z1lYl3lBlvnSTRjoeJyO058kpVsPfff9/1IVB/Am1DvbYLL7ywQF9j0ElVnXV1iXcEG1tl007ub3/7mwuY6hcRKbfh47n94EdW4SJvG/Tl0Zw76pukEVTqS6FqWuTr13uufkzaWavPhT4XWiftaFq1amWpohAbSUf9Wve8UKVMgS5eCM4LbS8FbFVvFG70r94D7aQjv6Oqyqnq+n//93+u6qjqjjo4q19MXj7vRfE9TIYCm+h1xoabRCmIBaFJwVqvUWFQHfNz+71E4SPcoECoI6l+oNQxL6iy5JWqB3qsyJ2k5o+QoIOoJkDTj4c6AUfasWNHnobFBs0qqkAFo8BEzS6qDOVn7pLY59HOInboe+zILR3JLliwwFVuVL0IaP0KkrazOnlqW95xxx05/q7gqGaO2HCjHYF2tFo3VST0Yx57NK73IlLskfThrFixwr3n6uCsKkxATQO5ff5UvdFF20hhUE0DBTG6KK9i1/X000/P82MFc6Wo43VBUFDUjlgds9WpVqFFTSqxHfEVeBQAdNHtdFDx4IMPus/w4apWeRX5PYylkXixt1WnfTXVRVZvVq1aFfVYR+rMHlTFCoq2z5QpU+yhhx464oSOKDz0uUGB0JG8jli0M449CtP12OHLRxq5Ezn0U80iqhJohxU0Nei5Yp9HP9Q6ss8LHWGpSUkzu+7fvz+8XMOWY3fS+aGdkwKTfvwCqkKo+SfeEW7sa4xsNigIGvmipj6FF5XnYy9qmtCOTO9JLFVINPpMc7FoTo+Adipafx0NR1ITYqLivX79X5WiSAqJag6IDTra2e3bt89SSTv/yEtsJSdRqkApZOrAIRgmXxD03up9VZOMpiLQ9SONFtJ3UApr22ob6TkUaiObXhUUNQoyUjBxnkb0RdIoKR0YqV/RkWjSSimog5egr5JGg6mKqP5DSA0qNygQ2qE8+uijbkennaXmetEORlUPBRW1S2tHmAhVfjS0U0NV1Y9Ck8ppqHdkZz4ddWp4qnbKKqvrSF8VhkT7x8RS3xqtv36UVLnRD73WXc+Z18eMR9tFzXuqMKhao+YW9SkJdiRBtUp9XNTmr6GyCkPqo6SmgMg5hQqCtpmChPofxKPOljoSVb+fQYMG5fi7hg1rJ6QO0Xq/NaxflRw1b2jYtl6PPhvqwBnbb+hwtF10P31mFFi1PdQ8Ftv3RtUdVRXUhKcOp+q/o8+bPi/q9J5u1KyryoMqCnoNCjbasSsw6nNSkJNHBvMKaRvrM6Dh15H0/VJA1WdDz6/3TwFV/aM0bL+wqElRz6nnULOzvhv6LKnyFVlhUdOaKo76fOo3RwFF3xF1gFZTpT4/kfQ5Cip5OoBRoNP0Ear0xmuSUnU43szBai6NnLoinoEDB7oDEU1Boe8Oih7hBgVGTRMKJjpyUgVHNLKqW7dubieZTBu2fszU10SlaB2xqmweWZLXnB8aQaMmFf1Ns4SqX0Bk80iyFMB0JKgdtp5bEwRqh6IKRUHRTkTrqR8/HZ2q7K+RYRpxcdZZZ0XtvPTa9KOrqo6qFtqO2vnFNh3klUKTql0Kh+qzFI8mUNP2104hXrgRVbu001HQ1M5SE+jp/dPj62/qU6Pwoe2qx0s0bOqoWiNhtLPTdtF20vnMIo+y9fnSnDxqwlPTjcKNgpH6kMTurNNB0ASpzvZ6T/QZ1E4y2LYFSdtU30sFXFWWYjsr628KDTq40Eg1hQCNkNN3uzDm8gmoT5k+l2rW0cGSQooOMhRaIieG1HdH309tM/0G6DZqttbnLDjNQiRVUdQRPrivXo8qzqqK6eAhkRF8okrmkcKNvqPXXXed+0yqs3Zs0ELhK6Hx4EXwPAAOQ51htfPWObsUcgAAeUe4AYqY5tSIHC2mapGqMpprR8OH8zuSDACOdjRLAUVMTU0KODqPjzpmagJEDfnWSBSCDQDkH5UboIipL42GKatDsUb6aEi12vfVnwQAkOZDwdUTXz3e1flKoyrU7+BI1KFMnUfVSVE7hcgzDAPpQB0NNRusRhmpcqMp4Ak2AOBJuNFoF418iJ3jIzcaBqshghr+p57vGu6nqcE1nwAAAECxapZS5UbzU2gekNxoGnYNo125cmV4meay0CRrzAQJAADSrkOxTvIWO+W35j5RBSc3KvtHzqap2WA1KZROrpjbOXAAAEDxolqMTrehrixHOnlrWoUbDZONnTxJ1zU9f+zw2oAmAAsmlAMAAOlt/fr1bqZsb8JNXmiGy8iZVdWJs0GDBq7/TkHP+AkAAAqHqjaaMT2RfXdahRudNFHnW4mk6zrvTG7zg2hUlS6xNLW57gcAAIo/nZZFEulSklZnBdekZzqHTCSdVE7LAQAAUh5udLI9DekOTguvpiL9Pzs7O9yk1KdPn/Dtb7vtNlu7dq3dd9997sy5OkOtTpB3zz33pOw1AACA4iWl4Ubn0mnVqpW7iPrG6P/BmXE3btwYDjqitjYNBVe1RvPjaJbXZ599Nups0QAA4OhWbOa5KSoaWZWRkeE6FtPnBgAA//bfadXnBgAA4EgINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeSXm4mThxojVs2NDKly9v7du3t6VLlx729uPHj7fTTjvNKlSoYPXr17d77rnHfv755yJbXwAAULylNNzMmDHDBg0aZEOHDrWsrCxr0aKFde/e3bZs2RL39tOmTbPMzEx3+y+++MKee+459xgPPPBAka87AAAonlIabp588km75ZZbrF+/fta0aVObNGmSVaxY0Z5//vm4t3///fftrLPOsuuuu85Ve7p162a9e/c+YrUHAAAcPUqn6on3799vy5Yts8GDB4eXlSxZ0rp27WpLliyJe58zzzzTXnzxRRdm2rVrZ2vXrrU5c+bYDTfckOvz7Nu3z10Cu3btcv8eOHDAXQAAQPGXzD47ZeFm27ZtdvDgQatVq1bUcl1ftWpV3PuoYqP7derUyUKhkP3yyy922223HbZZatSoUTZs2LAcy+fNm+eqRAAAoPjbu3dv8Q83ebFw4UIbOXKkPf30067z8Zo1a2zgwIE2YsQIe/jhh+PeR5Uh9euJrNyoI7KatKpUqVKEaw8AAPIqaHkp1uGmevXqVqpUKdu8eXPUcl2vXbt23PsowKgJ6re//a273rx5c9uzZ4/deuut9uCDD7pmrVjlypVzl1hlypRxFwAAUPwls89OWYfismXLWuvWrW3BggXhZYcOHXLXO3bsmGtJKjbAKCCJmqkAAABS2iyl5qK+fftamzZtXAdhzWGjSoxGT0mfPn2sXr16rt+MXHbZZW6EVatWrcLNUqrmaHkQcgAAwNEtpeGmV69etnXrVhsyZIht2rTJWrZsaXPnzg13Ms7Ozo6q1Dz00ENWokQJ9++GDRusRo0aLtg89thjKXwVAACgOCkROsrac9QhKSMjw3bu3EmHYgAAPNx/p/z0CwAAAAWJcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADglZSHm4kTJ1rDhg2tfPny1r59e1u6dOlhb79jxw678847rU6dOlauXDk79dRTbc6cOUW2vgAAwJNwo9Bx8ODB8PU33njDzj77bKtXr561adPG/va3vyX95DNmzLBBgwbZ0KFDLSsry1q0aGHdu3e3LVu2xL39/v377YILLrB169bZv/71L1u9erVNmTLFrQMAAICUCIVCoUQ2RalSpWzjxo1Ws2ZNe/31161nz552/fXXu2rLxx9/bC+88IL985//tCuuuCLhLav7tm3b1iZMmOCuHzp0yOrXr2/9+/e3zMzMHLefNGmSPfHEE7Zq1SorU6ZMnt7BXbt2WUZGhu3cudOqVKmSp8cAAABFK5n9d8LhpmTJkrZp0yYXbjp37mydOnWyUaNGhf8+cuRIF3qWLFmS0EqqClOxYkVXgVFQCvTt29c1Pb366qs57nPxxRdb1apV3f309xo1ath1111n999/vwtf8ezbt89dIjeOAtS2bdsINwAApAntv6tXr55QuCmdlyf48ssvbfz48VHLrrrqKldVSZTChZq5atWqFbVc11WZiWft2rX29ttv229+8xvXz2bNmjV2xx132IEDB1zTVjwKYMOGDcuxfN68eS4kAQCA4m/v3r0J3zapcPP555+76k2FChVcE1KsX375xQqTnlOVo8mTJ7tKTevWrW3Dhg0uVOUWbgYPHuz69cRWbrp160blBgCANKH9d6GEm/PPP9+CVqz33nvP9ZcJqN9NgwYNEn4slZYUUDZv3hy1XNdr164d9z4aIaW+NpFNUE2aNHGBS81cZcuWzXEfjajSJZYeJ6/9dgAAQNFKZp+d8Gipb775xjUL6V9dbrjhhqi/K1yo70uiFERUeVmwYEFUZUbXO3bsGPc+Z511lmuKiqwaqYlMoSdesAEAAEefhDsUFwYNBVcH4r/85S/Wrl07149HI67U50Z9b/r06eOGeQcdl9evX2+nn366u49GVH311Vd200032YABA+zBBx9M6DkZLQUAQPpJZv+dpw7Fe/bscc1SP/zwg5188smuApMXvXr1sq1bt9qQIUNc01LLli1t7ty54U7G2dnZbpRWQH1l/v3vf9s999xjZ5xxhgs+AwcOTKpiBAAA/JZ05ebJJ5+0xx57zJo1a+b6xnzyySd2/PHH26xZs9KiEkLlBgCA9JPM/jup0y+o6WfatGluLpv//Oc/rllJTUiaWVjVFPn+++/zt/YAAABFUbn54IMP7PLLL7fPPvvMnfYg8lQMSlG9e/d2k++1atXKzTisUzMUR1RuAABIP4XS50anPrjrrrvcEG7NCrxw4UI3QkkXPZH63SjcqIIzYsSIYhtuAACA3xJulnr//ffdPDfBOaE0Ykkdirdv325PPfWU1a1b1wWfK6+80hYvXhx1ygMAAIBiF24UYo499lj3/6lTp7qh2MGEOjoFgk6HoFMq6DYlSpRwo6AAAACKbbjRaQ80NFuOO+44V8kJfPjhh+7fypUruzYxTeinE1wCAAAUtYT73JxzzjnuTNwXXnihDR8+3PW7mT17tlWqVMmdhFLndtJpDrRM89VwUkoAAFCsR0vppJkdOnRw55A66aST7Ouvv3ahRlWaTp06uQ7FP/30kzvf1H333edmFy6OGC0FAED6SWb/ndQkfqNHj7bnn3/eVWeaNm0a9TeNlLr22mutfPny7u/FFeEGAID0U2inX8jMzHT9arp06WLnnXeenXnmmVahQgVbvny5zZw506655hobN25cftcfAACgaE+c+b///c+dbmHFihX2yy+/uPNL9ejRwzVXFXdUbgAASD+F1izlA8INAADpp9DOLSUNGzZ0o6XWr1+fn3UEAAAoFEmHm7vvvtteeeUVa9SokV1wwQU2ffp0ZiMGAADpHW4++eQTW7p0qTVp0sTNVFynTh133qmsrKzCWUsAAIAE5bvPzYEDB+zpp5+2+++/3/2/efPmNmDAAOvXr587DUNxQ58bAADST6ENBY+kIKMRUzrP1FtvveUm+Lv55pvtu+++swceeMDmz59v06ZNy+vDAwAA5EnS4UZNTwo0L730kpUsWdLNRKy5bRo3bhy+zRVXXOFmKgYAACj24UahRR2Jn3nmGevZs2f4zOCR1NlYsxUDAAAU+3Czdu1aO+GEEw57G51MU9UdAACAYj9aasuWLfbf//43x3It++ijjwpqvQAAAIom3Nx5551xJ/DbsGGD+xsAAEBahZvPP//cfvWrX+VY3qpVK/c3AACAtAo35cqVs82bN+dYvnHjRitdOs8jywEAAFITbrp162aDBw92k+gEduzY4ea20SgqAACAVEq61DJ27Fjr0qWLGzGlpijR6Rhq1aplf//73wtjHQEAAAov3NSrV8+WL19u//jHP+zTTz+1ChUquFMt9O7dO+6cNwAAAEUpT51kNI/NrbfeWvBrAwAAkE957gGskVHZ2dm2f//+qOU9evTI7zoBAAAU7QzFOnfUihUr3Fm/g5OKB2cAP3jwYN7XBgAAoKhHSw0cONCdO0ozFVesWNE+++wzW7RokbVp08YWLlyY3/UBAAAo2srNkiVL7O2337bq1au7s4Lr0qlTJxs1apQNGDDAPv744/ytEQAAQFFWbtTsVLlyZfd/BZzvv//e/V9Dw1evXp2fdQEAACj6yk2zZs3cEHA1TbVv397GjBljZcuWtcmTJ9uJJ56Y/zUCAAAoynDz0EMP2Z49e9z/hw8fbpdeeql17tzZqlWrZjNmzMjPugAAAORbiVAw3Ckftm/fbscdd1x4xFRxtmvXLsvIyHCnj6hSpUqqVwcAABTw/jupPjcHDhxwJ8dcuXJl1PKqVaumRbABAAD+Syrc6PQKDRo0YC4bAADgz2ipBx980J0BXE1RAAAAad+heMKECbZmzRqrW7euG/6t80xFysrKKsj1AwAAKNxw07Nnz2TvAgAAkF6jpdIJo6UAAEg/hTZaCgAAwLtmKZ1L6nDDvhlJBQAAUinpcDNr1qwcc9/oZJl//etfbdiwYQW5bgAAAKnrczNt2jR3+oVXX33VijP63AAAkH5S0uemQ4cOtmDBgoJ6OAAAgDwpkHDz008/2Z/+9CerV69eQTwcAABA0fW5iT1Bplq1du/ebRUrVrQXX3wx72sCAACQinAzbty4qHCj0VM1atSw9u3bu+ADAACQVuHmxhtvLJw1AQAASEWfm6lTp9rMmTNzLNcyDQcHAABIq3AzatQoq169eo7lNWvWtJEjRxbUegEAABRNuMnOzrZGjRrlWK4zhOtvAAAAaRVuVKFZvnx5juWffvqpVatWraDWCwAAoGjCTe/evW3AgAH2zjvvuPNI6fL222/bwIED7dprr83bWgAAAKRqtNSIESNs3bp1dv7551vp0v/f3Q8dOmR9+vShzw0AAEjfc0t99dVX9sknn1iFChWsefPmrs9NOuDcUgAApJ9k9t9JV24Cp5xyirsAAACkdZ+bq666yh5//PEcy8eMGWO//vWvC2q9AAAAiibcLFq0yC6++OIcyy+66CL3NwAAgLQKNz/++KOVLVs2x/IyZcq49jAAAIC0CjfqPDxjxowcy6dPn25NmzYtqPUCAAAomnDz8MMPu+Hgffv2deeS0kXDwB999FH3t7yYOHGiNWzY0MqXL+/OLr506dKE7qdApTOU9+zZM0/PCwAA/JN0uLnsssts9uzZtmbNGrvjjjvs3nvvtQ0bNriJ/E4++eSkV0BVoEGDBtnQoUMtKyvLWrRoYd27d7ctW7Yc9n6aa+f3v/+9de7cOennBAAA/srzPDcB9bN56aWX7LnnnrNly5a5GYuToUpN27ZtbcKECeEJAevXr2/9+/e3zMzMuPfRc3Tp0sVuuukmW7x4se3YscMFrnj27dvnLpHrq8fftm0b89wAAJAmtP/WibsLdZ4bjYxSoHn55Zetbt26duWVV7rmpWTs37/fBaLBgweHl5UsWdK6du1qS5YsyfV+w4cPd+e4uvnmm124OdJZzIcNG5Zj+bx586xixYpJrS8AAEiNvXv3JnzbpMLNpk2b7IUXXnChRgnqmmuucVURVU3y0plY1RNVYWrVqhW1XNdXrVoV9z7vvvuue37NjpwIBSc1e8VWbrp160blBgCANJHMiOzSyfS1UbXmkksusfHjx9uFF15opUqVskmTJllR2b17t91www02ZcoUV5pKRLly5dwl3tB1XQAAQPGXzD474XDz5ptvurOB33777QV22gUFFAWkzZs3Ry3X9dq1a+e4/ddff+06EitoBdRHR3QSz9WrV9tJJ51UIOsGAAA8Hy2l5iBVTlq3bu06AasDsJqV8kOTAerxFixYEBVWdL1jx445bt+4cWNbsWKFa5IKLj169LBzzz3X/V/NTQAA4OiWcLjp0KGDaw7auHGj/e53v3NzzKgjscLIW2+95YJPXqg/jB5X8+V88cUXrjK0Z88e69evn/u75tAJOhxrHpxmzZpFXY499lirXLmy+3+8mZMBAMDRJel5bipVquSGYKuSoyqK5rkZPXq0G72kKkqyevXqZWPHjrUhQ4ZYy5YtXQVm7ty54U7G2dnZLlABAAAUyTw3ohFPr7/+uj3//PP22muvWXHvbZ2RkZHQOHkAAJB+++8CCTfphHADAIDf+++km6UAAACKM8INAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8Ui3AzceJEa9iwoZUvX97at29vS5cuzfW2U6ZMsc6dO9txxx3nLl27dj3s7QEAwNEl5eFmxowZNmjQIBs6dKhlZWVZixYtrHv37rZly5a4t1+4cKH17t3b3nnnHVuyZInVr1/funXrZhs2bCjydQcAAMVPiVAoFErlCqhS07ZtW5swYYK7fujQIRdY+vfvb5mZmUe8/8GDB10FR/fv06dPjr/v27fPXQK7du1yj79t2zarUqVKAb8aAABQGLT/rl69uu3cufOI++/SlkL79++3ZcuW2eDBg8PLSpYs6ZqaVJVJxN69e+3AgQNWtWrVuH8fNWqUDRs2LMfyefPmWcWKFfOx9gAAoKhof5+olIYbVU9UealVq1bUcl1ftWpVQo9x//33W926dV0gikfBSc1esZUbNWVRuQEAID1o/50W4Sa/Ro8ebdOnT3f9cNQZOZ5y5cq5S6wyZcq4CwAAKP6S2WenNNyo7axUqVK2efPmqOW6Xrt27cPed+zYsS7czJ8/384444xCXlMAAJAuUjpaqmzZsta6dWtbsGBBeJk6FOt6x44dc73fmDFjbMSIETZ37lxr06ZNEa0tAABIBylvllJ/mL59+7qQ0q5dOxs/frzt2bPH+vXr5/6uEVD16tVzHYPl8ccftyFDhti0adPc3DibNm1yy4855hh3AQAAR7eUh5tevXrZ1q1bXWBRUGnZsqWryASdjLOzs90IqsAzzzzjRlldffXVUY+jeXIeeeSRIl9/AABQvKR8nptU9LbOyMhIaJw8AABIv/13ymcoBgAAKEiEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeKRbhZuLEidawYUMrX768tW/f3pYuXXrY28+cOdMaN27sbt+8eXObM2dOka0rAAAo3lIebmbMmGGDBg2yoUOHWlZWlrVo0cK6d+9uW7ZsiXv7999/33r37m0333yzffzxx9azZ093WblyZZGvOwAAKH5KhEKhUCpXQJWatm3b2oQJE9z1Q4cOWf369a1///6WmZmZ4/a9evWyPXv22BtvvBFe1qFDB2vZsqVNmjTpiM+3a9cuy8jIsJ07d1qVKlUK+NUAAIDCkMz+u7Sl0P79+23ZsmU2ePDg8LKSJUta165dbcmSJXHvo+Wq9ERSpWf27Nlxb79v3z53CWijyPbt2+3AgQMF9EoAAEBh2r17t/s3kZpMSsPNtm3b7ODBg1arVq2o5bq+atWquPfZtGlT3NtreTyjRo2yYcOG5VjeqFGjfK07AABITchRBafYhpuioKpQZKVHzV6q2lSrVs1KlCiR0nVD4Zcw1cS5fv16miABj/FdPzqEQiEXbOrWrXvE26Y03FSvXt1KlSplmzdvjlqu67Vr1457Hy1P5vblypVzl0jHHntsvtcd6UM/dvzgAf7ju+6/jCNUbIrFaKmyZcta69atbcGCBVGVFV3v2LFj3PtoeeTt5a233sr19gAA4OiS8mYpNRn17dvX2rRpY+3atbPx48e70VD9+vVzf+/Tp4/Vq1fP9Z2RgQMH2tlnn21//OMf7ZJLLrHp06fbRx99ZJMnT07xKwEAAMVBysONhnZv3brVhgwZ4joFa0j33Llzw52Gs7Oz3QiqwJlnnmnTpk2zhx56yB544AE75ZRT3EipZs2apfBVoDhSc6TmT4ptlgTgF77rKHbz3AAAAHg1QzEAAEBBItwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg2KBZ0K43CXRx55xNatWxf3b9dff32uj7tw4UJ3mx07dkRd10VTDGi2y1atWtl9991nGzdujLqvnjPe882fP7/QtwdwNLnxxhujvmM6Pc6FF15oy5cvD98mt98GzXUW+93WpUaNGnbxxRfbihUrEv6NgT9SPs8NIJHBYsaMGW7eo9WrV4eXHXPMMe5Eq6Jwcfrpp4f/VqFChaSfT4+tadp1TpqsrCwbM2aMPffcc+4Hsnnz5uHb6Xliw0zVqlWTfj4Ah6cwM3XqVPd/zXmmucwuvfRSN9dZQH/X7Q53Op3gu/3999/bH/7wBzfZ65o1axL6jYE/CDcoFiLPDaZqio6kYs8XFoQbHdXldi6xRNWsWdP9KOpxTj31VLv88stdBef222+3d999N3y70qVL5/u5AByZJuALvmv6NzMz0zp37uwmeVUVRoLvbKLf7bvvvtt69Ohhq1atsjPOOOOIvzHwB81SwP9f/bntttvsvffesy1btqR6dYCj2o8//mgvvviinXzyye5gJi927twZbrLSeQxxdKFyg7SjU3BEnpJj8eLFruqSX40bN3b/qm+Pjv5E7fWR5eqmTZva0qVL8/1cAKK98cYb4e+azi9Yp04dtyzyu967d28rVapU1P0+//xza9CgQfj68ccfH34MUeUm+G7j6EG4QdpRe3mTJk3C1+vXrx/uH/Ptt9+6/6uc/eabbyb1uMGZSFSuDpx22mn22muvha9z7hqgcJx77rn2zDPPuP//8MMP9vTTT9tFF13kDiZOOOEEt3zcuHHWtWvXqPvVrVs36roOdipWrGgffPCBjRw50iZNmlSErwLFBeEGaUdhRuXqWHPmzLEDBw7kuZPxF1984f5t2LBheJnK2fGeC0DBqlSpUtR37dlnn3V9Y6ZMmWKPPvqoW6Y+Mkf6PjZq1Mj1udGBiZqYdXLmRYsWFfr6o3ihzw28oaM7/fDpUq9evaTu+9NPP9nkyZOtS5cu4c6LAFInmK5B3828uvPOO23lypU2a9asAl03FH9UbnBU0hHdzz//bLt377Zly5a5oeAajfXKK6+ketWAo9K+ffvcEPCgWWrChAmuY/Fll10Wvo3mqwpuE6hcubKr+sSj5qlbbrnFhg4daj179oxqcobfqNzgqKSStdrqW7dubaNHj3bt+DrCU4dhAEVv7ty5rhOxLu3bt7cPP/zQZs6caeecc074Nv369QvfJrj8+c9/Puzj3nXXXa7JWY+Fo0eJUNCLEgAAwANUbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAABgPvl/onTV54naopoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "methods = ['TF-IDF', 'BERT']\n",
    "accuracies = [acc_tfidf, acc_bert]\n",
    "\n",
    "plt.bar(methods, accuracies, color=['skyblue', 'orange'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy@5\")\n",
    "plt.title(\"Perbandingan Akurasi TF-IDF vs IndoBERT\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
